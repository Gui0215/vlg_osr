dataset: 
  dataset: imagenet-100
  image_size: 64
  out_num:

model:
  backbone: resnet18
  ckpt_pretrained:
  feat_dim: 512

aug:
  transform: imagenet
  rand_aug_m: 
  rand_aug_n: 

train:
  seed: 0
  n_epochs: 100
  amp: False  # set this to True, if your GPU supports FP16. 2080Ti - okay, 1080Ti - not okay
  ema: False  # optional, but I recommend it, since the training might get unstable otherwise
  ema_decay_per_epoch: 0.3  # 0.3 for middle/big datasets. Increase, if you have low amount of samples
  target_metric: auroc
  stage: first  # first = Supcon, second = FC finetuning for classification


dataloaders:
  batch_size: 256 # the higher - the better
  num_workers: 12 # set this to num of threads in your CPU

optimizer:
  name: SGD # or Adam
  lr: 0.1
  weight_decay: 1e-4

scheduler:
  name: CosineAnnealingLR
  params:
    T_max: 100
    eta_min: 0.01
    step: 30
    num_restarts: 3

criterion:
  name: 'Softmax'
  params:
    temperature: 0.1

log:
  dir: '/home/gui/Downloads/vlg_osr/log'
